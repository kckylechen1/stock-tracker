/**
 * GLM æ¨¡å‹æµ‹è¯•è„šæœ¬
 * æµ‹è¯•æ™ºè°±AIçš„å„ä¸ªæ¨¡å‹æ˜¯å¦å¯ç”¨
 */

import "dotenv/config";

const GLM_API_URL =
  process.env.GLM_API_URL || "https://open.bigmodel.cn/api/paas/v4";
const GLM_API_KEY = process.env.GLM_API_KEY || "";

// è¦æµ‹è¯•çš„æ¨¡å‹åˆ—è¡¨
const MODELS_TO_TEST = [
  "glm-4.7", // ä½ é…ç½®çš„æ¨¡å‹
  "glm-4-flash", // å…è´¹æ¨¡å‹
  "glm-4-air", // é«˜æ€§ä»·æ¯”
  "glm-4", // æ ‡å‡†ç‰ˆ
];

async function testModel(model: string): Promise<void> {
  console.log(`\nğŸ§ª æµ‹è¯•æ¨¡å‹: ${model}`);
  console.log("-".repeat(40));

  try {
    const response = await fetch(`${GLM_API_URL}/chat/completions`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${GLM_API_KEY}`,
      },
      body: JSON.stringify({
        model: model,
        messages: [{ role: "user", content: "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±" }],
        max_tokens: 100,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.log(`âŒ å¤±è´¥ (${response.status}): ${errorText}`);
      return;
    }

    const data = await response.json();
    const content = data.choices?.[0]?.message?.content || "æ— å“åº”";
    const usage = data.usage;

    console.log(`âœ… æˆåŠŸ!`);
    console.log(`ğŸ“ å›å¤: ${content.substring(0, 100)}...`);
    if (usage) {
      console.log(
        `ğŸ“Š Token: prompt=${usage.prompt_tokens}, completion=${usage.completion_tokens}`
      );
    }
  } catch (error: any) {
    console.log(`âŒ é”™è¯¯: ${error.message}`);
  }
}

async function main() {
  console.log("=".repeat(50));
  console.log("ğŸ”¬ æ™ºè°±AI GLM æ¨¡å‹æµ‹è¯•");
  console.log("=".repeat(50));
  console.log(`API URL: ${GLM_API_URL}`);
  console.log(`API Key: ${GLM_API_KEY.substring(0, 10)}...`);

  for (const model of MODELS_TO_TEST) {
    await testModel(model);
  }

  console.log("\n" + "=".repeat(50));
  console.log("æµ‹è¯•å®Œæˆ!");
}

main();
